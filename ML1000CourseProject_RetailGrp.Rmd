---
title: "Course Project ML1000 - Retail Group"
author: "Retail Group: Ignacio Palma, Jairo Melo, Mahboob Jamil, Vikram Khade"
output: github_document
Objective: Service Desk Tickets Analysis to resolved business questions about improving reliability while reducing cost
---

```{r libraries, include=FALSE}
#knitr::opts_chunk$set(echo = FALSE)

library(lattice)
library(ggplot2)
library(caret)
library(randomForest)
library(dplyr)
library(tidyverse)  # data manipulation
library(cluster)    # clustering algorithms
library(factoextra) # clustering visualization
library(dendextend) # for comparing two dendrograms
library(fpc)
library(stats)    #   clustering algorithms
library(gower) # for using Gower to introduce categorical values with Hierarchical CLustering
library(StatMatch) # for using Gower to introduce categorical values with Hierarchical CLustering
library(NbClust)
library(stringi)
library(RColorBrewer)
library(scales)
library(rpart)
library(rpart.plot)

```

## Information Technology Service Management Analysis

ITSM is an area of continues improvement and for major organizations every opportunity could represent major cost savings which translate into more affortable products for patiences and parents.

The file extracted from the ITSM system contains 1.2 year worth data for two major product lines.

## Loading data

You can include R code in the document as follows:

```{r loadingData, echo=FALSE}

getwd();
#setwd('/Users/jairomelo/Desktop/ML/YORK/Assigment2/CourseProject')
sdata=read.csv("~/desktop/ML/YORK/CourseProject/Support Tickets Dataset- ML.csv", header = TRUE, dec = ".")

```

## Cleaning the data
Remove any duplicated or missing observations if there is any.
```{r pressure, echo=FALSE}
nrow(sdata)
sdata <- distinct(sdata)

#Removing observations where tickets are not closed
#TSdata <- TSdata[TSdata$resolved != '',]
sdata <- sdata[which(sdata$resolved != "" ),]
sdata <- sdata[which(sdata$res_category != "" ),]
nrow(sdata)

#Though sdata is complete, We check if some rows containing NULL or weid entries are caught by this command.
sum(!complete.cases(sdata))


```


## Data Understanding

* incident: Number of the ticket incident.  Not a significant variable as is sequencial counter.
* application: Number of the application of the reported issue.  This is a relevant variable which a certantly number of tickets are assigned to one application.
* region: Region where the Application is supported.  Significant as a region is associated to a particular population of users reporting issues of an application.
* prod_line: Category of the Application: These are two major Production Line which the applications belong to.
* opened: Date when the issues was opened.  The ticket has 5 stages:  Not Assigned, In Progress, Customer Action, Pending, Resolved, Closed.

Not Assigned: The ticket was created/open, but still not been worked by the support team.
In Progress: The ticket is assigned to a support group who is actively working on it.
Customer Action: The ticket goes into a stand-by because additional information is requested from the user before the current support group can continue working.
Pending: The ticket goes into a stand-by because there is an activity to be performed by a third party group before the current support group can continue working.
Resolved: Once the issue is fixed, the user is notified by the Support team.
Closed: Each resolved ticket moves into Closed after the user confirms, or automatically, the ticket is closed after n number of days.

* app_category: Category of the Application.  Relevant as this is the classification of the application.
* priority: Priority of the Issue.  This is the result of Urgency and Impact.  
Low Urgency - Limited Impact = Lower Priority. -> 4
High Urgency - Limite Impact = High Priority. -> 1
The "Priority" word can be removed from the field and use the numbers 1,2,3,4.  Priority 4 is low, and 1 is the highest.
* urgency: How soon the issue should be resolved.  There is a strong correlation between Urgency and Priority; which might cause to ommit the field when using Priority.
* impact: What's the extension of the issue in terms of number of users.  eg: Limited means small group usually 1 or 2 users, Spread-out means usually an area, department or even all organization.  There is a strong correlation between Urgency and Priority; which might cause to ommit the field when using Priority.
* Closed: Date when the ticket was finally closed.  Refer to the Opened field for explanation of the stages of the tickets.
* sup_grp: Support Group providing resolution to the issue.  This is relevant as the support group is responsible to effectively close a ticket as soon as it's assigned.
* grp_level: Support Group Level.  There are 3 different support levels.  

Level 1: Service Desk, primary group who handles all tickets and try to troubleshot the issue.  Most of the tickets should be filtered by this team.  This is less specialized team, and help to keep Level 2 and 3 focus on major activities.
Level 2: This is the specialist team who has greater knowledge on how the application operates.  This team takes care of tickets Level 1 is not able to resolved.
Level 3: This is the Developers of the applications; has complete knowledge of the application and finally able to resolve the issues scalated by L2 team.

The "Level" word can be removed from the field and use the numbers 1,2,3.  Level 1 is the less specialized, and 3 is the most specialized, usually a lot more expensive than 1.

* resolved: Date when the issue was resolved.  Refer to the Opened field for explanation of the stages of the tickets.
* res_category: Category of the type of resolution support team completed.
* cust_time: Time in seconds the ticket was waiting for Customer response.  Refer to the Opened field for explanation of the stages of the tickets.
* pend_time: Time ticket is on hold.  Refer to the Opened field for explanation of the stages of the tickets.
* call_log: Id of the phone call When a call is involved.  Not a relevant attribute as not all tickets triggers a phone call.
* chat_log: If of the chat session when user uses instance message with the support team.  This new technology is not heavily used, so there are very few observations with this information.

Let's chart the data to understand more about the variables associated to the support activities

## Data Visualization
Let's review what the data can tell us about supporting applications for JTS:


```{r sup_level, echo=FALSE}

barplot(table(sdata$app_category))


```
```{r sup_level, echo=FALSE}

pieGRP <- table(sdata$grp_level)
pct <- round(pieGRP/sum(pieGRP)*100)
lbls <- paste(names(pieGRP), "\n", pieState, sep="")
lbls <- paste(lbls, pct) # add percents to labels 
lbls <- paste(lbls,"%",sep="") # ad % to labels 
pie(pieGRP,labels = lbls, col=rainbow(length(lbls)),main="Pie by Group Level")
pieGRP

```


```{r support group, echo=FALSE}
plot(table(sdata$priority))
```
```{r support group, echo=FALSE}
plot(table(sdata$grp_level))
```

Plot by Resolution Category

```{r support group, echo=FALSE}
plot(table(sdata$res_category))
```



## Data Preparation

Below attributes will be removed from the Dataset due to the low analytical value:
Incident
call_log
chat_log

```{r removefield, echo=FALSE}


#Remove irrelevant features
sdata <- select(sdata,-incident)
sdata <- select(sdata,-cust_time)
sdata <- select(sdata,-pend_time)
sdata <- select(sdata,-call_log)
sdata <- select(sdata,-chat_log)
sdata <- select(sdata,-Closed)
```

We will remove the words "Priority"" and "Level"" to allow the numberic be part of the analysis:
```{r removing, echo=FALSE}
#Removing any other groups that re not under ITSM Governance
sdata <- subset(sdata, grp_level=='Level 1' | grp_level=='Level 2' | grp_level=='Level 3')


sdata["impactN"] <- "NA"
sdata[sdata$impact=="Limited","impactN"] <- as.numeric(1) 
sdata[sdata$impact=="Large","impactN"] <- as.numeric(2)
sdata[sdata$impact=="Widespread","impactN"] <- as.numeric(3)

sdata["urgencyN"] <- "NA"
sdata[sdata$urgency=="Low","urgencyN"] <- as.numeric(1) 
sdata[sdata$urgency=="Medium","urgencyN"] <- as.numeric(2)
sdata[sdata$urgency=="High","urgencyN"] <- as.numeric(3)

sdata["priorityN"] <- "NA"
sdata[sdata$priority=="Priority 4","priorityN"] <- as.numeric(1) 
sdata[sdata$priority=="Priority 3","priorityN"] <- as.numeric(2)
sdata[sdata$priority=="Priority 2","priorityN"] <- as.numeric(3)

sdata$impactN <- as.numeric(sdata$impactN)
sdata$urgencyN <- as.numeric(sdata$urgencyN)
sdata$priorityN <- as.numeric(sdata$priorityN)


nrow(sdata)

```

Now we will create the numeric representation of the Date variables:

```{r dat_num, echo=FALSE}

#Creation of a new variable called MTTR (Mean Time To Resolution)= Resolved time - Open Time

sdata$MTTR <- difftime(sdata$resolved,sdata$opened,tz="GMT",units="secs")

#Priority 1 is the lowest and Priority 3 is the highest

sdata$SLA <- ifelse(sdata$priorityN == 3 & sdata$MTTR < 28801, "Gold", ifelse(sdata$priorityN == 2 & sdata$MTTR < 144001, "Silver", ifelse(sdata$priorityN == 1 & sdata$MTTR < 288001, "Bronze",ifelse(sdata$priorityN == 1 & sdata$MTTR < 432001, "Iron", "FAILED"))))

sdata$SLA <- factor(sdata$SLA)

summary(sdata$SLA)

pieGRP <- table(sdata$SLA)
pct <- round(pieGRP/sum(pieGRP)*100)
lbls <- paste(names(pieGRP), "\n", pieState, sep="")
lbls <- paste(lbls, pct) # add percents to labels 
lbls <- paste(lbls,"%",sep="") # ad % to labels 
pie(pieGRP,labels = lbls, col=rainbow(length(lbls)),main="Pie by SLA")
pieGRP

```
{
```{r}

#convert dates to date objects
sdata["open_date"] <- "NA"
sdata["open_date"] <- as.Date(as.character(sdata[,"opened"]),"%Y-%m-%d")
sdata["resolve_date"] <- "NA"
sdata["resolve_date"] <- as.Date(as.character(sdata[,"resolved"]),"%Y-%m-%d")

#Calculate days required to close a ticket
sdata["ndays"] <- "NA"
sdata["ndays"] <- as.numeric(sdata[,"resolve_date"] - sdata[,"open_date"])



```


```{r}

#Convert ordinal level to numeric and save in new feature
sdata["levelN"] <- as.numeric(0)
sdata[sdata$grp_level=="Level 1","levelN"] <- as.numeric(1) 
sdata[sdata$grp_level=="Level 2","levelN"] <- as.numeric(2)
sdata[sdata$grp_level=="Level 3","levelN"] <- as.numeric(3)

#drop low frequency level for certain features. Threshold = 2.5%
perc <- round(nrow(sdata)*2.5/100)

tt <- table(sdata$app_category)
rare_levels <- names(tt)[tt<perc]
sdata <- subset(sdata,!app_category %in% rare_levels)
sdata$app_category <- factor(sdata$app_category)

tt <- table(sdata$res_category)
rare_levels <- names(tt)[tt<perc]
sdata <- subset(sdata,!res_category %in% rare_levels)
sdata$res_category <- factor(sdata$res_category)

tt <- table(sdata$region)
rare_levels <- names(tt)[tt<perc]
sdata <- subset(sdata,!region %in% rare_levels)
sdata$region <- factor(sdata$region)


```

```{r sup_level, echo=FALSE}



```




```{r}
savedir <- ""

pp <- ggplot(sdata, aes(x=application)) + geom_bar(aes(y=..count../sum(..count..)),col='violet',fill='violet') + 
  coord_flip()

pp <- ggplot(sdata, aes(x=sup_grp)) + geom_bar(aes(y=..count../sum(..count..)),col='coral4',fill='coral4') + 
  coord_flip()

fnm <- paste(c(savedir,'app_category_hori.pdf'),collapse='')

pdf(fnm)
pp <- ggplot(sdata, aes(x=app_category)) + geom_bar(aes(y=..count../sum(..count..)),col='coral4',fill='coral4') + 
     coord_flip() 
print(pp)
dev.off()

fnm <- paste(c(savedir,'priority_hori.pdf'),collapse='')
pdf(fnm)
pp <- ggplot(sdata, aes(x=priority)) + geom_bar(aes(y=..count../sum(..count..)),col='black',fill='chocolate') + 
   coord_flip()
print(pp)
dev.off()

fnm <- paste(c(savedir,'priorityN_hori.pdf'),collapse='')
pdf(fnm)
pp <- ggplot(sdata, aes(x=priorityN)) + geom_bar(aes(y=..count../sum(..count..)),col='black',fill='chocolate') + 
  coord_flip()
print(pp)
dev.off()

fnm <- paste(c(savedir,'res_category_hori.pdf'),collapse='')
pdf(fnm)
pp <- ggplot(sdata, aes(x=res_category)) + geom_bar(aes(y=..count../sum(..count..)),col='black',fill='deeppink') + 
  coord_flip()
print(pp)
dev.off()

fnm <- paste(c(savedir,'urgency_hori.pdf'),collapse='')
pdf(fnm)
pp <- ggplot(sdata, aes(x=urgency)) + geom_bar(aes(y=..count../sum(..count..)),col='black',fill='deeppink') + 
  coord_flip()
print(pp)
dev.off()

fnm <- paste(c(savedir,'urgencyN_hori.pdf'),collapse='')
pdf(fnm)
pp <- ggplot(sdata, aes(x=urgencyN)) + geom_bar(aes(y=..count../sum(..count..)),col='black',fill='deeppink') + 
  coord_flip()
print(pp)
dev.off()



fnm <- paste(c(savedir,'prod_line_hori.pdf'),collapse='')
pdf(fnm)
pp <- ggplot(sdata, aes(x=prod_line)) + geom_bar(aes(y=..count../sum(..count..)),col='black',fill='firebrick1') + 
  coord_flip()
print(pp)
dev.off()

fnm <- paste(c(savedir,'impact_hori.pdf'),collapse='')
pdf(fnm)
pp <- ggplot(sdata, aes(x=impact)) + geom_bar(aes(y=..count../sum(..count..)),col='black',fill='goldenrod') + 
  coord_flip()
print(pp)
dev.off()

fnm <- paste(c(savedir,'impactN_hori.pdf'),collapse='')
pdf(fnm)
pp <- ggplot(sdata, aes(x=impactN)) + geom_bar(aes(y=..count../sum(..count..)),col='black',fill='goldenrod') + 
  coord_flip()
print(pp)
dev.off()

fnm <- paste(c(savedir,'grp_level_hori.pdf'),collapse='')
pdf(fnm)
pp <- ggplot(sdata, aes(x=grp_level)) + geom_bar(aes(y=..count../sum(..count..)),col='black',fill='deepskyblue') + 
      coord_flip() 
print(pp)
dev.off()

fnm <- paste(c(savedir,'region_hori.pdf'),collapse='')
pdf(fnm)
pp <- ggplot(sdata, aes(x=region)) + geom_bar(aes(y=..count../sum(..count..)),col='black',fill='darkorange') + 
  coord_flip() 
print(pp)
dev.off()




#Since priority and urgency are highly correlated (0.89) urgency is dropped from further analysis.
sdata <- select(sdata,-urgencyN)
sdata <- select(sdata,-urgency)


```

# Supervised Learning


##Feature selection
Let's run a random forest to quantify the relative importance of these features
```{r}
set.seed(719)
rfImp <- randomForest(SLA ~ priority + app_category + res_category + grp_level + region + prod_line, data = sdata, ntree = 100, importance = TRUE)
importance(rfImp,type=2)

```

We will use supervised algorithms to model the 

#This is to use the same data set for Training and Test

```{r supervised, echo=FALSE}
splitIndex <- createDataPartition(sdata[,'SLA'], p = .75, list = FALSE, times = 1)
trainDF <- sdata[ splitIndex,]
testDF  <- sdata[-splitIndex,]

set.seed(152)

rparTree <- rpart(SLA ~ priority + app_category + res_category + grp_level + region, data=trainDF, control = rpart.control(cp = 0.0001))

```
## Visualize model
#################################################
```{r}
printcp(rparTree)

bestcp <- rparTree$cptable[which.min(rparTree$cptable[,"xerror"]),"CP"]

# Step3: Prune the tree using the best cp.
rparTree.pruned <- prune(rparTree, cp = bestcp)

# confusion matrix (training data)
conf.matrix <- table(sdata$SLA, predict(rparTree.pruned,type="class"))
rownames(conf.matrix) <- paste("Actual", rownames(conf.matrix), sep = ":")
colnames(conf.matrix) <- paste("Pred", colnames(conf.matrix), sep = ":")
print(conf.matrix)

plot(rparTree.pruned)
text(rparTree.pruned, cex = 0.8, use.n = TRUE, xpd = TRUE)

prp(rparTree.pruned, faclen = 0, cex = 0.8, extra = 1)

```

##Let's make a prediction (accuracy of testing dataset)

#a) Classification Tree / Recursive Partitioning and Confusion Matrix
```{r}
predictions <- predict(rparTree, testDF)
head(predictions)
confusionMatrix(predictions,testDF$SLA)
```

## Deployment
Predicting outcome of an unseen data point
```{r}
xnew = data[21170,c('priority','app_category','res_category','grp_level','region','prod_line')]
predict(fit.rf,xnew)


```