---
title: "Course Project ML1000 - Retail Group"
author: "Retail Group: Ignacio Palma, Jairo Melo, Mahboob Jamil, Vikram Khade"
output: github_document
Objective: Service Desk Tickets Analysis to resolved business questions about improving reliability while reducing cost
---

```{r libraries, include=FALSE}
#knitr::opts_chunk$set(echo = FALSE)

library(lattice)
library(ggplot2)
library(caret)
library(randomForest)
library(dplyr)

library(tidyverse)  # data manipulation
library(cluster)    # clustering algorithms
library(factoextra) # clustering visualization
library(dendextend) # for comparing two dendrograms

library(stats)    #   clustering algorithms
library(gower) # for using Gower to introduce categorical values with Hierarchical CLustering
library(StatMatch) # for using Gower to introduce categorical values with Hierarchical CLustering


```

## Information Technology Service Management Analysis

ITSM is an area of continues improvement and for major organizations every opportunity could represent major cost savings which translate into more affortable products for patiences and parents.

The file extracted from the ITSM system contains 1.2 year worth data for two major product lines.

## Loading data

You can include R code in the document as follows:

```{r loadingData, echo=FALSE}

getwd();
#setwd('/Users/jairomelo/Desktop/ML/YORK/Assigment2/CourseProject')
TSdata=read.csv("~/desktop/ML/YORK/CourseProject/Support Tickets Dataset- ML.csv", header = TRUE, dec = ".")

```

## Cleaning the data

Remove any duplicated or missing observations.

```{r pressure, echo=FALSE}
nrow(TSdata)
TSdata <- distinct(TSdata)

#Keeping only Observations where the tickets are Resolved.  Open tickets are not relevant.
TSdata <- TSdata[TSdata$resolved != '',]

```


## Data Understanding

* incident: Number of the ticket incident.  Not a significant variable as is sequencial counter.
* application: Number of the application of the reported issue.  This is a relevant variable which a certantly number of tickets are assigned to one application.
* region: Region where the Application is supported.  Significant as a region is associated to a particular population of users reporting issues of an application.
* prod_line: Category of the Application: These are two major Production Line which the applications belong to.
* opened: Date when the issues was opened.  The ticket has 5 stages:  Not Assigned, In Progress, Customer Action, Pending, Resolved, Closed.

Not Assigned: The ticket was created/open, but still not been worked by the support team.
In Progress: The ticket is assigned to a support group who is actively working on it.
Customer Action: The ticket goes into a stand-by because additional information is requested from the user before the current support group can continue working.
Pending: The ticket goes into a stand-by because there is an activity to be performed by a third party group before the current support group can continue working.
Resolved: Once the issue is fixed, the user is notified by the Support team.
Closed: Each resolved ticket moves into Closed after the user confirms, or automatically, the ticket is closed after n number of days.

* app_category: Category of the Application.  Relevant as this is the classification of the application.
* priority: Priority of the Issue.  This is the result of Urgency and Impact.  
Low Urgency - Limited Impact = Lower Priority. -> 4
High Urgency - Limite Impact = High Priority. -> 1
The "Priority" word can be removed from the field and use the numbers 1,2,3,4.  Priority 4 is low, and 1 is the highest.
* urgency: How soon the issue should be resolved.  There is a strong correlation between Urgency and Priority; which might cause to ommit the field when using Priority.
* impact: What's the extension of the issue in terms of number of users.  eg: Limited means small group usually 1 or 2 users, Spread-out means usually an area, department or even all organization.  There is a strong correlation between Urgency and Priority; which might cause to ommit the field when using Priority.
* Closed: Date when the ticket was finally closed.  Refer to the Opened field for explanation of the stages of the tickets.
* sup_grp: Support Group providing resolution to the issue.  This is relevant as the support group is responsible to effectively close a ticket as soon as it's assigned.
* grp_level: Support Group Level.  There are 3 different support levels.  

Level 1: Service Desk, primary group who handles all tickets and try to troubleshot the issue.  Most of the tickets should be filtered by this team.  This is less specialized team, and help to keep Level 2 and 3 focus on major activities.
Level 2: This is the specialist team who has greater knowledge on how the application operates.  This team takes care of tickets Level 1 is not able to resolved.
Level 3: This is the Developers of the applications; has complete knowledge of the application and finally able to resolve the issues scalated by L2 team.

The "Level" word can be removed from the field and use the numbers 1,2,3.  Level 1 is the less specialized, and 3 is the most specialized, usually a lot more expensive than 1.

* resolved: Date when the issue was resolved.  Refer to the Opened field for explanation of the stages of the tickets.
* res_category: Category of the type of resolution support team completed.
* cust_time: Time in seconds the ticket was waiting for Customer response.  Refer to the Opened field for explanation of the stages of the tickets.
* pend_time: Time ticket is on hold.  Refer to the Opened field for explanation of the stages of the tickets.
* call_log: Id of the phone call When a call is involved.  Not a relevant attribute as not all tickets triggers a phone call.
* chat_log: If of the chat session when user uses instance message with the support team.  This new technology is not heavily used, so there are very few observations with this information.

Let's chart the data to understand more about the variables associated to the support activities

## Data Visualization
Let's review what the data can tell us about supporting applications for JTS:


```{r sup_level, echo=FALSE}

barplot(table(TSdata$res_category))


```
```{r sup_level, echo=FALSE}

pieGRP <- table(TSdata$grp_level)
pct <- round(pieGRP/sum(pieGRP)*100)
lbls <- paste(names(pieGRP), "\n", pieState, sep="")
lbls <- paste(lbls, pct) # add percents to labels 
lbls <- paste(lbls,"%",sep="") # ad % to labels 
pie(pieGRP,labels = lbls, col=rainbow(length(lbls)),main="Pie by Group Level")
pieGRP

```


```{r support group, echo=FALSE}
plot(table(TSdata$sup_grp))
```
```{r support group, echo=FALSE}
plot(table(TSdata$sup_grp))
```

## Data Preparation

Below attributes will be removed from the Dataset due to the low analytical value:
Incident
call_log
chat_log

```{r removefield, echo=FALSE}
TSdata <- select(TSdata,-incident)
TSdata <- select(TSdata,-call_log)
TSdata <- select(TSdata,-chat_log)
#TSdata <- select(TSdata,-impact)
TSdata <- select(TSdata,-region)
TSdata <- select(TSdata,-pend_time)
TSdata <- select(TSdata,-cust_time)
```

We will remove the words "Priority"" and "Level"" to allow the numberic be part of the analysis:
```{r removing, echo=FALSE}


#Since this is a snapshot of today's tickets status, 455 tickets have no Resolution time.  Those observations can be removed from the dataset

#Transforming Urgency where 1 is the lowest and 3 is the highest
summary(TSdata$urgency)
TSdata$urgency <- ifelse(TSdata$urgency == 'Low',1,ifelse(TSdata$priority == 'Medium 3',2,3))
summary(TSdata$urgency)

#Transforming Priority to Lowest 1 and hiest 3
summary(TSdata$priority)
TSdata$priority <- ifelse(TSdata$priority == 'Priority 4',1,ifelse(TSdata$priority == 'Priority 3',2,3))
summary(TSdata$priority)

#Transforming Group Level to number and removing any observations different than the 3 grp levels
summary(TSdata$grp_level)
TSdata <- subset(TSdata, grp_level=='Level 1' | grp_level=='Level 2' | grp_level=='Level 3')
TSdata$grp_level <- as.numeric(gsub("Level ", "", TSdata$grp_level))
summary(TSdata$grp_level)

```

Now we will create the numeric representation of the Date variables:

```{r dat_num, echo=FALSE}

#Creation of a new variable called MTTR (Mean Time To Resolution)= Resolved time - Open Time

TSdata$MTTR <- difftime(TSdata$resolved,TSdata$opened,tz="GMT",units="secs")

```
## Supervised Learning

Our target variable will be Level2 and Leve3 of Support Group Level.  In order to predict more accurally how many L2 Resources we will need next year, we will create a target value called Level2 and train are predictor.

```{r supervised, echo=FALSE}

TSdata$level3 <- ifelse(TSdata$grp_level == 3,1,0)
TSdata$level2 <- ifelse(TSdata$grp_level == 2,1,0)

```

We will use supervised algorithms to model the 

#This is to use the same data set for Training and Test

```{r supervised, echo=FALSE}
splitIndex <- createDataPartition(TSdata[,'grp_level2'], p = .75, list = FALSE, times = 1)
trainDF <- TSdata[ splitIndex,]
testDF  <- TSdata[-splitIndex,]
summary(trainDF)
summary(testDF)

# a) Linear Discriminant Analysis
trctl <- trainControl(method = 'cv', number = 10, savePredictions = TRUE)
metric <- "Accuracy"

set.seed(152)
fit.lda <- train(level2 ~ application + prod_line + priority, app_category + res_category + cust_time + pend_time + application + region, data=trainDF, method="lda", metric=metric, trControl=trctl)

# b) Nonlinear algorithms Classification Tree / Recursive Partitioning
set.seed(152)
fit.cart <- train(level3 ~ res_category + cust_time + pend_time + application + region, data=trainDF, method="rpart", metric=metric, trControl=trctl)
  
# c) Final algorithm Random Forest
set.seed(152)
fit.rf <- train(level3 ~ res_category + cust_time + pend_time + application + region, data=trainDF, method="rf", metric=metric, trControl=trctl)
  
```
## Evalutate model
#################################################
#summarize accuracy of models (Training)
```{r}
results <- resamples(list(lda=fit.lda, cart=fit.cart, rf=fit.rf))
summary(results)

## Visualize the accuracy of the models
dotplot(results)
```

##Let's make a prediction (accuracy of testing dataset)

#a) Linear Discriminant Analysis and Confusion Matrix
```{r}
predictions <- predict(fit.lda, testDF)
head(predictions)
confusionMatrix(predictions,testDF$state)
```
#b) Classification Tree / Recursive Partitioning and Confusion Matrix
```{r}
predictions <- predict(fit.cart, testDF)
head(predictions)
confusionMatrix(predictions,testDF$state)
```
#c) Final algorithm Random Forest and confusion matrix
```{r}
predictions <- predict(fit.rf, testDF)
head(predictions)
confusionMatrix(predictions,testDF$state)

```

